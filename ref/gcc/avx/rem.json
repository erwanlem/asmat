{
    "function": "rem",
    "asm": [
        {
            "type": [
                "std::int64_t",
                "std::int64_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vmovq %xmm1,%rcx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vmovq %xmm0,%rax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "cqto",
                "idivq %rcx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrq $1,%xmm1,%rcx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movq %rdx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%ymm5",
                "vpextrq $1,%xmm5,%rax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "cqto",
                "idivq %rcx",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovq %xmm1,%rcx",
                "movq %rdx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vmovq %xmm0,%rax",
                "vmovdqa %xmm2,(%rsp)",
                "cqto",
                "idivq %rcx",
                "vpextrq $1,%xmm1,%rcx",
                "movq %rdx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrq $1,%xmm0,%rax",
                "vmovdqa %xmm2,(%rsp)",
                "cqto",
                "idivq %rcx",
                "movq %rdx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L127",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L127:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::int32_t",
                "std::int32_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vmovd %xmm1,%ecx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vmovd %xmm0,%eax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "cltd",
                "idivl %ecx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrd $1,%xmm1,%ecx",
                "movl %edx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm5",
                "vpextrd $1,%xmm0,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "cltd",
                "idivl %ecx",
                "vmovdqa %xmm7,16(%rsp)",
                "vpextrd $2,%xmm1,%ecx",
                "movl %edx,52(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm3",
                "vpextrd $2,%xmm0,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "cltd",
                "idivl %ecx",
                "vmovdqa %xmm5,16(%rsp)",
                "vpextrd $3,%xmm1,%ecx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movl %edx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm6",
                "vpextrd $3,%xmm0,%eax",
                "vmovdqu %ymm6,48(%rsp)",
                "cltd",
                "idivl %ecx",
                "vmovd %xmm1,%ecx",
                "movl %edx,60(%rsp)",
                "vmovdqa 48(%rsp),%xmm7",
                "vmovdqa %xmm7,(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vmovd %xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cltd",
                "idivl %ecx",
                "vpextrd $1,%xmm1,%ecx",
                "movl %edx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $1,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cltd",
                "idivl %ecx",
                "vpextrd $2,%xmm1,%ecx",
                "movl %edx,68(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $2,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cltd",
                "idivl %ecx",
                "vpextrd $3,%xmm1,%ecx",
                "movl %edx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $3,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cltd",
                "idivl %ecx",
                "movl %edx,76(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L131",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L131:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::int16_t",
                "std::int16_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vpextrw $0,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vpextrw $0,%xmm0,%eax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "cwtl",
                "cltd",
                "vmovdqa %xmm4,16(%rsp)",
                "idivl %ecx",
                "vpextrw $1,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm5",
                "vpextrw $1,%xmm2,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "cwtl",
                "cltd",
                "vmovdqa %xmm7,16(%rsp)",
                "idivl %ecx",
                "vpextrw $2,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,50(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm3",
                "vpextrw $2,%xmm2,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "cwtl",
                "cltd",
                "vmovdqa %xmm5,16(%rsp)",
                "idivl %ecx",
                "vpextrw $3,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,52(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm6",
                "vpextrw $3,%xmm2,%eax",
                "vmovdqu %ymm6,48(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $4,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,54(%rsp)",
                "vmovdqa 48(%rsp),%xmm7",
                "vmovdqa %xmm7,(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa (%rsp),%xmm2",
                "vpextrw $4,%xmm2,%eax",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm4",
                "cwtl",
                "cltd",
                "vmovdqu %ymm4,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "idivl %ecx",
                "vmovdqa %xmm6,16(%rsp)",
                "vpextrw $5,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm5",
                "vmovdqa %xmm5,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm7",
                "vpextrw $5,%xmm2,%eax",
                "vmovdqu %ymm7,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "cwtl",
                "cltd",
                "vmovdqa %xmm4,16(%rsp)",
                "idivl %ecx",
                "vpextrw $6,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,58(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm5",
                "vpextrw $6,%xmm2,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "cwtl",
                "cltd",
                "vmovdqa %xmm7,16(%rsp)",
                "idivl %ecx",
                "vpextrw $7,%xmm1,%ecx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movswl %cx,%ecx",
                "movw %dx,60(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm3",
                "vpextrw $7,%xmm2,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $0,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,62(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $0,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $1,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $1,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $2,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,66(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $2,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $3,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,68(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $3,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $4,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,70(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $4,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $5,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $5,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $6,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,74(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $6,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "vpextrw $7,%xmm1,%ecx",
                "movswl %cx,%ecx",
                "movw %dx,76(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $7,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "cwtl",
                "cltd",
                "idivl %ecx",
                "movw %dx,78(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L135",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L135:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::int8_t",
                "std::int8_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "addq $-128,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,120(%rsp)",
                "xorl %eax,%eax",
                "leaq 32(%rsp),%rax",
                "vmovdqa %ymm0,32(%rsp)",
                "leaq 16(%rsp),%rdi",
                "vmovq %rax,%xmm0",
                "leaq 64(%rsp),%rax",
                "vmovdqa %ymm1,64(%rsp)",
                "vpinsrq $1,%rax,%xmm0,%xmm0",
                "vmovdqa %xmm0,16(%rsp)",
                "vzeroupper",
                "call _ZZN3eve6detail8self_remIaNS_10avx_abi_v04wideIaNS_5fixedILl32EEEEES5_EEDcRNS3_IT_T1_EERKT0_ENKUlDpT_E_clIJSt17integral_constantImLm0EESI_ImLm1EESI_ImLm2EESI_ImLm3EESI_ImLm4EESI_ImLm5EESI_ImLm6EESI_ImLm7EESI_ImLm8EESI_ImLm9EESI_ImLm10EESI_ImLm11EESI_ImLm12EESI_ImLm13EESI_ImLm14EESI_ImLm15EESI_ImLm16EESI_ImLm17EESI_ImLm18EESI_ImLm19EESI_ImLm20EESI_ImLm21EESI_ImLm22EESI_ImLm23EESI_ImLm24EESI_ImLm25EESI_ImLm26EESI_ImLm27EESI_ImLm28EESI_ImLm29EESI_ImLm30EESI_ImLm31EEEEEDaSF_.isra.0",
                "vmovdqa 32(%rsp),%ymm0",
                "movq 120(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L139",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L139:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::uint64_t",
                "std::uint64_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vmovq %xmm1,%rcx",
                "xorl %edx,%edx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vmovq %xmm0,%rax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "divq %rcx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrq $1,%xmm1,%rcx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movq %rdx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%ymm5",
                "vpextrq $1,%xmm5,%rax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "divq %rcx",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovq %xmm1,%rcx",
                "movq %rdx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vmovq %xmm0,%rax",
                "vmovdqa %xmm2,(%rsp)",
                "divq %rcx",
                "vpextrq $1,%xmm1,%rcx",
                "movq %rdx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrq $1,%xmm0,%rax",
                "vmovdqa %xmm2,(%rsp)",
                "divq %rcx",
                "movq %rdx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L143",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L143:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::uint32_t",
                "std::uint32_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vmovd %xmm1,%ecx",
                "xorl %edx,%edx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vmovd %xmm0,%eax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "divl %ecx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrd $1,%xmm1,%ecx",
                "movl %edx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm5",
                "vpextrd $1,%xmm0,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "divl %ecx",
                "vmovdqa %xmm7,16(%rsp)",
                "vpextrd $2,%xmm1,%ecx",
                "movl %edx,52(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm3",
                "vpextrd $2,%xmm0,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "divl %ecx",
                "vmovdqa %xmm5,16(%rsp)",
                "vpextrd $3,%xmm1,%ecx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movl %edx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "xorl %edx,%edx",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa (%rsp),%xmm0",
                "vmovdqa (%rsp),%ymm6",
                "vpextrd $3,%xmm0,%eax",
                "vmovdqu %ymm6,48(%rsp)",
                "divl %ecx",
                "vmovd %xmm1,%ecx",
                "movl %edx,60(%rsp)",
                "vmovdqa 48(%rsp),%xmm7",
                "xorl %edx,%edx",
                "vmovdqa %xmm7,(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vmovd %xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divl %ecx",
                "vpextrd $1,%xmm1,%ecx",
                "movl %edx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "xorl %edx,%edx",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $1,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divl %ecx",
                "vpextrd $2,%xmm1,%ecx",
                "movl %edx,68(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "xorl %edx,%edx",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $2,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divl %ecx",
                "vpextrd $3,%xmm1,%ecx",
                "movl %edx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrd $3,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divl %ecx",
                "movl %edx,76(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L147",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L147:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::uint16_t",
                "std::uint16_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "vpextrw $0,%xmm1,%ecx",
                "xorl %edx,%edx",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "subq $96,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,88(%rsp)",
                "xorl %eax,%eax",
                "vpextrw $0,%xmm0,%eax",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "divw %cx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrw $1,%xmm1,%ecx",
                "movw %dx,48(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm5",
                "vpextrw $1,%xmm2,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "divw %cx",
                "vmovdqa %xmm7,16(%rsp)",
                "vpextrw $2,%xmm1,%ecx",
                "movw %dx,50(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm3",
                "vpextrw $2,%xmm2,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "divw %cx",
                "vmovdqa %xmm5,16(%rsp)",
                "vpextrw $3,%xmm1,%ecx",
                "movw %dx,52(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "xorl %edx,%edx",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm6",
                "vpextrw $3,%xmm2,%eax",
                "vmovdqu %ymm6,48(%rsp)",
                "divw %cx",
                "vpextrw $4,%xmm1,%ecx",
                "movw %dx,54(%rsp)",
                "vmovdqa 48(%rsp),%xmm7",
                "xorl %edx,%edx",
                "vmovdqa %xmm7,(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa (%rsp),%xmm2",
                "vpextrw $4,%xmm2,%eax",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm4",
                "divw %cx",
                "vmovdqu %ymm4,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "vmovdqa %xmm6,16(%rsp)",
                "vpextrw $5,%xmm1,%ecx",
                "movw %dx,56(%rsp)",
                "vmovdqa 48(%rsp),%xmm5",
                "xorl %edx,%edx",
                "vmovdqa %xmm5,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm7",
                "vpextrw $5,%xmm2,%eax",
                "vmovdqu %ymm7,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "divw %cx",
                "vmovdqa %xmm4,16(%rsp)",
                "vpextrw $6,%xmm1,%ecx",
                "movw %dx,58(%rsp)",
                "vmovdqa 48(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm5",
                "vpextrw $6,%xmm2,%eax",
                "vmovdqu %ymm5,48(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "divw %cx",
                "vmovdqa %xmm7,16(%rsp)",
                "vpextrw $7,%xmm1,%ecx",
                "vextractf128 $0x1,%ymm1,%xmm1",
                "movw %dx,60(%rsp)",
                "vmovdqa 48(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,(%rsp)",
                "vmovdqa (%rsp),%xmm2",
                "vmovdqa (%rsp),%ymm3",
                "vpextrw $7,%xmm2,%eax",
                "vmovdqu %ymm3,48(%rsp)",
                "divw %cx",
                "vpextrw $0,%xmm1,%ecx",
                "movw %dx,62(%rsp)",
                "vmovdqa 48(%rsp),%xmm4",
                "xorl %edx,%edx",
                "vmovdqa %xmm4,(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $0,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $1,%xmm1,%ecx",
                "movw %dx,64(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $1,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $2,%xmm1,%ecx",
                "movw %dx,66(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "xorl %edx,%edx",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $2,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $3,%xmm1,%ecx",
                "movw %dx,68(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "xorl %edx,%edx",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $3,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $4,%xmm1,%ecx",
                "movw %dx,70(%rsp)",
                "vmovdqa 64(%rsp),%xmm4",
                "xorl %edx,%edx",
                "vmovdqa %xmm4,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $4,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $5,%xmm1,%ecx",
                "movw %dx,72(%rsp)",
                "vmovdqa 64(%rsp),%xmm5",
                "xorl %edx,%edx",
                "vmovdqa %xmm5,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $5,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $6,%xmm1,%ecx",
                "movw %dx,74(%rsp)",
                "vmovdqa 64(%rsp),%xmm6",
                "xorl %edx,%edx",
                "vmovdqa %xmm6,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $6,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "vpextrw $7,%xmm1,%ecx",
                "movw %dx,76(%rsp)",
                "vmovdqa 64(%rsp),%xmm7",
                "xorl %edx,%edx",
                "vmovdqa %xmm7,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "vmovdqu %ymm0,48(%rsp)",
                "vmovdqa %xmm0,%xmm2",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpextrw $7,%xmm0,%eax",
                "vmovdqa %xmm2,(%rsp)",
                "divw %cx",
                "movw %dx,78(%rsp)",
                "vmovdqa 64(%rsp),%xmm3",
                "vmovdqa %xmm3,16(%rsp)",
                "vmovdqa (%rsp),%ymm0",
                "movq 88(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L151",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L151:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        },
        {
            "type": [
                "std::uint8_t",
                "std::uint8_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                ".cfi_offset6,-16",
                "movq %rsp,%rbp",
                ".cfi_def_cfa_register6",
                "andq $-32,%rsp",
                "addq $-128,%rsp",
                "movq %fs:40,%rax",
                "movq %rax,120(%rsp)",
                "xorl %eax,%eax",
                "leaq 32(%rsp),%rax",
                "vmovdqa %ymm0,32(%rsp)",
                "leaq 16(%rsp),%rdi",
                "vmovq %rax,%xmm0",
                "leaq 64(%rsp),%rax",
                "vmovdqa %ymm1,64(%rsp)",
                "vpinsrq $1,%rax,%xmm0,%xmm0",
                "vmovdqa %xmm0,16(%rsp)",
                "vzeroupper",
                "call _ZZN3eve6detail8self_remIhNS_10avx_abi_v04wideIhNS_5fixedILl32EEEEES5_EEDcRNS3_IT_T1_EERKT0_ENKUlDpT_E_clIJSt17integral_constantImLm0EESI_ImLm1EESI_ImLm2EESI_ImLm3EESI_ImLm4EESI_ImLm5EESI_ImLm6EESI_ImLm7EESI_ImLm8EESI_ImLm9EESI_ImLm10EESI_ImLm11EESI_ImLm12EESI_ImLm13EESI_ImLm14EESI_ImLm15EESI_ImLm16EESI_ImLm17EESI_ImLm18EESI_ImLm19EESI_ImLm20EESI_ImLm21EESI_ImLm22EESI_ImLm23EESI_ImLm24EESI_ImLm25EESI_ImLm26EESI_ImLm27EESI_ImLm28EESI_ImLm29EESI_ImLm30EESI_ImLm31EEEEEDaSF_.isra.0",
                "vmovdqa 32(%rsp),%ymm0",
                "movq 120(%rsp),%rax",
                "subq %fs:40,%rax",
                "jne .L155",
                "leave",
                ".cfi_remember_state",
                ".cfi_def_cfa7,8",
                ".L155:",
                ".cfi_restore_state",
                "vzeroupper",
                "call __stack_chk_fail@PLT"
            ]
        }
    ]
}