{
    "function": "average",
    "asm": [
        {
            "type": [
                "float",
                "float"
            ],
            "instr": [
                "vmovaps .LCPI189_0(%rip),%ymm2",
                "vmulps %ymm2,%ymm1,%ymm1",
                "vmulps %ymm2,%ymm0,%ymm0",
                "vaddps %ymm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "double",
                "double"
            ],
            "instr": [
                "vmovapd .LCPI190_0(%rip),%ymm2",
                "vmulpd %ymm2,%ymm1,%ymm1",
                "vmulpd %ymm2,%ymm0,%ymm0",
                "vaddpd %ymm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::int64_t",
                "std::int64_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vextractf128 $1,%ymm0,%xmm1",
                "vpsrad $1,%xmm1,%xmm3",
                "vpsrlq $1,%xmm1,%xmm1",
                "vpblendw $204,%xmm3,%xmm1,%xmm1",
                "vpsrad $1,%xmm0,%xmm3",
                "vpsrlq $1,%xmm0,%xmm0",
                "vpblendw $204,%xmm3,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddq %xmm3,%xmm1,%xmm1",
                "vpaddq %xmm2,%xmm0,%xmm0",
                "vinsertf128 $1,%xmm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::int32_t",
                "std::int32_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vpsrad $1,%xmm0,%xmm1",
                "vextractf128 $1,%ymm0,%xmm0",
                "vpsrad $1,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddd %xmm3,%xmm0,%xmm0",
                "vpaddd %xmm2,%xmm1,%xmm1",
                "vinsertf128 $1,%xmm0,%ymm1,%ymm0"
            ]
        },
        {
            "type": [
                "std::int16_t",
                "std::int16_t"
            ],
            "instr": [
                "pushq %rbx",
                ".cfi_def_cfa_offset16",
                ".cfi_offset%rbx,-16",
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm1",
                "vpextrq $1,%xmm1,%rsi",
                "vextractf128 $1,%ymm1,%xmm0",
                "vmovq %xmm0,%r11",
                "vpextrq $1,%xmm0,%rax",
                "vmovq %xmm1,%rcx",
                "movl %ecx,%edx",
                "shll $16,%edx",
                "movq %rax,%r8",
                "shrq $16,%r8",
                "movq %r11,%r9",
                "shrq $16,%r9",
                "movq %rsi,%r10",
                "shrq $16,%r10",
                "movq %rcx,%rdi",
                "shrq $16,%rdi",
                "vpextrd $1,%xmm1,%ebx",
                "vmovd %edx,%xmm3",
                "vpinsrd $1,%ecx,%xmm3,%xmm3",
                "vpinsrd $2,%edi,%xmm3,%xmm3",
                "vpinsrd $3,%ebx,%xmm3,%xmm3",
                "vpsrad $17,%xmm3,%xmm3",
                "shll $16,%eax",
                "movq %r11,%rdx",
                "shrq $48,%rdx",
                "orl %eax,%edx",
                "shll $16,%r11d",
                "movq %rsi,%rax",
                "shrq $48,%rax",
                "shll $16,%esi",
                "shrq $48,%rcx",
                "vpextrd $2,%xmm1,%edi",
                "orl %esi,%ecx",
                "vmovd %ecx,%xmm4",
                "vpinsrd $1,%edi,%xmm4,%xmm4",
                "orl %r11d,%eax",
                "vpinsrd $2,%r10d,%xmm4,%xmm4",
                "vpblendw $192,%xmm1,%xmm4,%xmm1",
                "vpsrad $17,%xmm1,%xmm1",
                "vpackssdw %xmm1,%xmm3,%xmm1",
                "vpextrd $1,%xmm0,%ecx",
                "vmovd %xmm0,%esi",
                "vmovd %eax,%xmm3",
                "vpinsrd $1,%esi,%xmm3,%xmm3",
                "vpinsrd $2,%r9d,%xmm3,%xmm3",
                "vpinsrd $3,%ecx,%xmm3,%xmm3",
                "vpsrad $17,%xmm3,%xmm3",
                "vpextrd $2,%xmm0,%eax",
                "vmovd %edx,%xmm4",
                "vpinsrd $1,%eax,%xmm4,%xmm4",
                "vpinsrd $2,%r8d,%xmm4,%xmm4",
                "vpackssdw %xmm3,%xmm3,%xmm3",
                "vpblendw $192,%xmm0,%xmm4,%xmm0",
                "vpsrad $17,%xmm0,%xmm0",
                "vpackssdw %xmm0,%xmm0,%xmm0",
                "vinsertf128 $1,%xmm0,%ymm0,%ymm0",
                "vinsertf128 $1,%xmm3,%ymm0,%ymm3",
                "vunpcklpd %ymm0,%ymm3,%ymm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vextractf128 $1,%ymm0,%xmm0",
                "vpaddw %xmm3,%xmm0,%xmm0",
                "vpaddw %xmm2,%xmm1,%xmm1",
                "vinsertf128 $1,%xmm0,%ymm1,%ymm0",
                "popq %rbx",
                ".cfi_def_cfa_offset8"
            ]
        },
        {
            "type": [
                "std::int8_t",
                "std::int8_t"
            ],
            "instr": [
                "pushq %rbp",
                ".cfi_def_cfa_offset16",
                "pushq %r15",
                ".cfi_def_cfa_offset24",
                "pushq %r14",
                ".cfi_def_cfa_offset32",
                "pushq %r13",
                ".cfi_def_cfa_offset40",
                "pushq %r12",
                ".cfi_def_cfa_offset48",
                "pushq %rbx",
                ".cfi_def_cfa_offset56",
                ".cfi_offset%rbx,-56",
                ".cfi_offset%r12,-48",
                ".cfi_offset%r13,-40",
                ".cfi_offset%r14,-32",
                ".cfi_offset%r15,-24",
                ".cfi_offset%rbp,-16",
                "vxorps %ymm0,%ymm1,%ymm3",
                "vpextrq $1,%xmm3,%rsi",
                "vextractf128 $1,%ymm3,%xmm15",
                "vmovq %xmm15,%rcx",
                "vpextrq $1,%xmm15,%r12",
                "vmovq %xmm3,%rdi",
                "vpshufb .LCPI194_0(%rip),%xmm3,%xmm4",
                "movl %edi,%edx",
                "shll $8,%edx",
                "vpinsrd $2,%edx,%xmm4,%xmm4",
                "vpinsrd $3,%edi,%xmm4,%xmm2",
                "vmovdqa %xmm2,-24(%rsp)",
                "movq %rsi,%r8",
                "movq %rcx,%r9",
                "shldq $48,%rsi,%r9",
                "movq %rcx,%r10",
                "shldq $40,%rsi,%r10",
                "movq %rsi,%r11",
                "shldq $48,%rdi,%r11",
                "movq %rsi,%rbx",
                "shldq $40,%rdi,%rbx",
                "movq %rsi,%r13",
                "movl %esi,%ebp",
                "movq %rcx,%r14",
                "shldq $16,%rsi,%r14",
                "movq %rcx,%r15",
                "shldq $8,%rsi,%r15",
                "movq %rsi,%rax",
                "shldq $16,%rdi,%rax",
                "shldq $8,%rdi,%rsi",
                "vmovq %rbx,%xmm4",
                "movq %rdi,%rbx",
                "shrq $8,%rbx",
                "vmovq %r11,%xmm5",
                "vpunpckldq %xmm4,%xmm5,%xmm4",
                "vpextrd $1,%xmm3,%r11d",
                "vpshufd $80,%xmm4,%xmm4",
                "vmovd %ebx,%xmm5",
                "vpblendw $3,%xmm5,%xmm4,%xmm4",
                "vpinsrd $3,%r11d,%xmm4,%xmm2",
                "vmovdqa %xmm2,-40(%rsp)",
                "movl %r12d,%edx",
                "shll $24,%edx",
                "movq %rcx,%rbx",
                "shrq $40,%rbx",
                "orl %edx,%ebx",
                "movl %ecx,%edx",
                "shll $24,%edx",
                "shrq $40,%r13",
                "orl %edx,%r13d",
                "shll $24,%ebp",
                "shrq $40,%rdi",
                "orl %ebp,%edi",
                "vmovq %rsi,%xmm4",
                "vmovq %rax,%xmm6",
                "vpunpckldq %xmm4,%xmm6,%xmm4",
                "vmovd %edi,%xmm6",
                "vpextrd $2,%xmm3,%eax",
                "vpshufd $80,%xmm4,%xmm4",
                "vpblendw $3,%xmm6,%xmm4,%xmm4",
                "vpinsrd $3,%eax,%xmm4,%xmm10",
                "vmovq %r10,%xmm11",
                "vmovq %r9,%xmm12",
                "movq %r12,%rsi",
                "shrq $8,%r8",
                "vmovq %r15,%xmm5",
                "movq %r12,%rax",
                "vmovq %r14,%xmm6",
                "movq %r12,%rdx",
                "vpunpckldq %xmm5,%xmm6,%xmm5",
                "vmovd %r13d,%xmm6",
                "vmovd %xmm15,%edi",
                "vpshufd $80,%xmm5,%xmm5",
                "vpblendw $3,%xmm6,%xmm5,%xmm5",
                "vpinsrd $3,%edi,%xmm5,%xmm13",
                "movq %r12,%rdi",
                "shldq $48,%rcx,%rdi",
                "vmovd %r8d,%xmm14",
                "movq %r12,%rbp",
                "shldq $40,%rcx,%rbp",
                "vmovq %rbp,%xmm7",
                "movq %r12,%rbp",
                "shldq $16,%rcx,%rbp",
                "shldq $8,%rcx,%r12",
                "vmovq %rdi,%xmm4",
                "shrq $8,%rcx",
                "vpunpckldq %xmm7,%xmm4,%xmm4",
                "vmovd %ecx,%xmm7",
                "vpextrd $1,%xmm15,%ecx",
                "vpshufd $80,%xmm4,%xmm4",
                "vpblendw $3,%xmm7,%xmm4,%xmm4",
                "vpinsrd $3,%ecx,%xmm4,%xmm9",
                "vmovq %r12,%xmm7",
                "vmovq %rbp,%xmm5",
                "vpunpckldq %xmm7,%xmm5,%xmm5",
                "vmovd %ebx,%xmm7",
                "vpextrd $2,%xmm15,%ecx",
                "vpshufd $80,%xmm5,%xmm5",
                "vpblendw $3,%xmm7,%xmm5,%xmm5",
                "vpinsrd $3,%ecx,%xmm5,%xmm8",
                "shrq $24,%rdx",
                "vmovq %rdx,%xmm7",
                "shrq $16,%rax",
                "vmovq %rax,%xmm6",
                "shrq $8,%rsi",
                "vmovd %esi,%xmm2",
                "vandps %ymm0,%ymm1,%ymm0",
                "vmovdqa -24(%rsp),%xmm1",
                "vpsrad $25,%xmm1,%xmm1",
                "vmovdqa -40(%rsp),%xmm4",
                "vpsrad $25,%xmm4,%xmm4",
                "vpackssdw %xmm4,%xmm1,%xmm1",
                "vpunpckldq %xmm11,%xmm12,%xmm4",
                "vpshufd $80,%xmm4,%xmm4",
                "vpblendw $3,%xmm14,%xmm4,%xmm4",
                "vpblendw $192,%xmm3,%xmm4,%xmm3",
                "vpsrad $25,%xmm13,%xmm4",
                "vpsrad $25,%xmm9,%xmm5",
                "vpackssdw %xmm5,%xmm4,%xmm4",
                "vpunpckldq %xmm7,%xmm6,%xmm5",
                "vpsrad $25,%xmm10,%xmm6",
                "vpsrad $25,%xmm3,%xmm3",
                "vpsrad $25,%xmm8,%xmm7",
                "vpshufd $80,%xmm5,%xmm5",
                "vpblendw $3,%xmm2,%xmm5,%xmm2",
                "vpblendw $192,%xmm15,%xmm2,%xmm2",
                "vpsrad $25,%xmm2,%xmm2",
                "vpackssdw %xmm2,%xmm7,%xmm2",
                "vpacksswb %xmm2,%xmm4,%xmm2",
                "vpackssdw %xmm6,%xmm6,%xmm4",
                "vpacksswb %xmm4,%xmm1,%xmm1",
                "vpshufb .LCPI194_1(%rip),%xmm3,%xmm3",
                "vpblendw $192,%xmm3,%xmm1,%xmm1",
                "vextractf128 $1,%ymm0,%xmm3",
                "vpaddb %xmm3,%xmm2,%xmm2",
                "vpaddb %xmm0,%xmm1,%xmm0",
                "vinsertf128 $1,%xmm2,%ymm0,%ymm0",
                "popq %rbx",
                ".cfi_def_cfa_offset48",
                "popq %r12",
                ".cfi_def_cfa_offset40",
                "popq %r13",
                ".cfi_def_cfa_offset32",
                "popq %r14",
                ".cfi_def_cfa_offset24",
                "popq %r15",
                ".cfi_def_cfa_offset16",
                "popq %rbp",
                ".cfi_def_cfa_offset8"
            ]
        },
        {
            "type": [
                "std::uint64_t",
                "std::uint64_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vextractf128 $1,%ymm0,%xmm1",
                "vpsrlq $1,%xmm1,%xmm1",
                "vpsrlq $1,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddq %xmm3,%xmm1,%xmm1",
                "vpaddq %xmm2,%xmm0,%xmm0",
                "vinsertf128 $1,%xmm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint32_t",
                "std::uint32_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vpsrld $1,%xmm0,%xmm1",
                "vextractf128 $1,%ymm0,%xmm0",
                "vpsrld $1,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddd %xmm3,%xmm0,%xmm0",
                "vpaddd %xmm2,%xmm1,%xmm1",
                "vinsertf128 $1,%xmm0,%ymm1,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint16_t",
                "std::uint16_t"
            ],
            "instr": [
                "vxorps %ymm0,%ymm1,%ymm2",
                "vmovq %xmm2,%rax",
                "movzwl %ax,%ecx",
                "shrl %ecx",
                "vmovd %ecx,%xmm3",
                "movl %eax,%ecx",
                "shrl $17,%ecx",
                "vpinsrw $1,%ecx,%xmm3,%xmm3",
                "vpextrw $2,%xmm2,%ecx",
                "shrl %ecx",
                "vpinsrw $2,%ecx,%xmm3,%xmm3",
                "vpextrq $1,%xmm2,%rcx",
                "vextractf128 $1,%ymm2,%xmm4",
                "shrq $49,%rax",
                "vpinsrw $3,%eax,%xmm3,%xmm3",
                "vpextrw $4,%xmm2,%eax",
                "shrl %eax",
                "vpinsrw $4,%eax,%xmm3,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $5,%ecx,%xmm3,%xmm3",
                "vpextrw $6,%xmm2,%ecx",
                "shrl %ecx",
                "vpinsrw $6,%ecx,%xmm3,%xmm2",
                "vmovq %xmm4,%rcx",
                "shrq $49,%rax",
                "vpinsrw $7,%eax,%xmm2,%xmm2",
                "vmovd %xmm4,%eax",
                "movzwl %ax,%eax",
                "shrl %eax",
                "vmovd %eax,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $1,%ecx,%xmm3,%xmm3",
                "vpextrw $2,%xmm4,%ecx",
                "shrl %ecx",
                "vpinsrw $2,%ecx,%xmm3,%xmm3",
                "vpextrq $1,%xmm4,%rcx",
                "shrq $49,%rax",
                "vpinsrw $3,%eax,%xmm3,%xmm3",
                "vpextrw $4,%xmm4,%eax",
                "shrl %eax",
                "vpinsrw $4,%eax,%xmm3,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $5,%ecx,%xmm3,%xmm3",
                "vpextrw $6,%xmm4,%ecx",
                "shrl %ecx",
                "vpinsrw $6,%ecx,%xmm3,%xmm3",
                "shrq $49,%rax",
                "vpinsrw $7,%eax,%xmm3,%xmm3",
                "vandps %ymm0,%ymm1,%ymm0",
                "vextractf128 $1,%ymm0,%xmm1",
                "vpaddw %xmm1,%xmm3,%xmm1",
                "vpaddw %xmm0,%xmm2,%xmm0",
                "vinsertf128 $1,%xmm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint8_t",
                "std::uint8_t"
            ],
            "instr": [
                "pushq %r15",
                ".cfi_def_cfa_offset16",
                "pushq %r14",
                ".cfi_def_cfa_offset24",
                "pushq %rbx",
                ".cfi_def_cfa_offset32",
                ".cfi_offset%rbx,-32",
                ".cfi_offset%r14,-24",
                ".cfi_offset%r15,-16",
                "vxorps %ymm0,%ymm1,%ymm4",
                "vextractf128 $1,%ymm4,%xmm2",
                "vpextrq $1,%xmm2,%r15",
                "vpextrq $1,%xmm4,%rsi",
                "vmovq %xmm2,%rdx",
                "vmovq %xmm4,%rdi",
                "movl %edi,%r8d",
                "movq %rdx,%r14",
                "shldq $47,%rsi,%r14",
                "movq %rsi,%rcx",
                "shldq $55,%rdi,%rcx",
                "shrb %r8b",
                "movq %rsi,%rbx",
                "shldq $47,%rdi,%rbx",
                "vmovq %rbx,%xmm3",
                "vmovq %rcx,%xmm5",
                "vpunpcklbw %xmm3,%xmm5,%xmm5",
                "vmovdqa .LCPI202_0(%rip),%xmm15",
                "vpand %xmm5,%xmm15,%xmm8",
                "movl %edi,%r9d",
                "movq %rdi,%r11",
                "movq %rsi,%rcx",
                "shldq $15,%rdi,%rcx",
                "shrdq $57,%rsi,%rdi",
                "shrl $25,%r9d",
                "vmovq %rdi,%xmm11",
                "movq %rdx,%rdi",
                "shldq $39,%rsi,%rdi",
                "vmovq %rcx,%xmm12",
                "movq %rdx,%r10",
                "vmovq %rdi,%xmm13",
                "movq %rdx,%rdi",
                "shldq $15,%rsi,%rdi",
                "vmovq %r14,%xmm14",
                "movq %rdx,%rcx",
                "shldq $7,%rsi,%rcx",
                "vmovq %rcx,%xmm9",
                "movq %rdx,%rcx",
                "vmovq %rdi,%xmm10",
                "movq %r15,%rdi",
                "shldq $47,%rdx,%rdi",
                "movzbl %r8b,%ebx",
                "vmovd %ebx,%xmm6",
                "movq %r15,%rax",
                "shldq $15,%rdx,%rax",
                "vpunpcklbw %xmm6,%xmm8,%xmm6",
                "vpshufb .LCPI202_1(%rip),%xmm6,%xmm6",
                "vpinsrb $3,%r9d,%xmm6,%xmm6",
                "movq %r15,%rbx",
                "shldq $7,%rdx,%rbx",
                "shrdq $25,%r15,%rdx",
                "vmovq %rdx,%xmm8",
                "vpextrb $4,%xmm4,%edx",
                "shrb %dl",
                "movzbl %dl,%edx",
                "vpinsrb $4,%edx,%xmm6,%xmm6",
                "shrq $41,%r11",
                "andb $127,%r11b",
                "movzbl %r11b,%edx",
                "vpinsrb $5,%edx,%xmm6,%xmm6",
                "vmovq %rdi,%xmm5",
                "vpunpcklbw %xmm11,%xmm12,%xmm3",
                "vpand %xmm3,%xmm15,%xmm3",
                "vpunpcklbw %xmm13,%xmm14,%xmm7",
                "vmovq %rbx,%xmm11",
                "vpextrb $8,%xmm4,%edx",
                "shrb %dl",
                "vpunpcklwd %xmm3,%xmm6,%xmm3",
                "vmovdqa .LCPI202_2(%rip),%xmm12",
                "vpshufb %xmm12,%xmm3,%xmm3",
                "movzbl %dl,%edx",
                "vpinsrb $8,%edx,%xmm3,%xmm3",
                "movq %rsi,%rdx",
                "shrq $9,%rsi",
                "andb $127,%sil",
                "vpand %xmm7,%xmm15,%xmm7",
                "movzbl %sil,%esi",
                "vpinsrb $9,%esi,%xmm3,%xmm3",
                "vpextrb $12,%xmm4,%esi",
                "shrb %sil",
                "vpslldq $10,%xmm7,%xmm4",
                "vpblendw $32,%xmm4,%xmm3,%xmm3",
                "movzbl %sil,%esi",
                "vpinsrb $12,%esi,%xmm3,%xmm3",
                "vmovq %rax,%xmm4",
                "vmovd %xmm2,%eax",
                "shrb %al",
                "movzbl %al,%eax",
                "vmovd %eax,%xmm7",
                "shrq $9,%rcx",
                "andb $127,%cl",
                "movzbl %cl,%eax",
                "vpinsrb $1,%eax,%xmm7,%xmm7",
                "movq %r15,%rax",
                "shrq $25,%rax",
                "vpunpcklbw %xmm8,%xmm5,%xmm5",
                "vmovq %rax,%xmm6",
                "movq %r15,%rax",
                "shrq $17,%rax",
                "vpand %xmm5,%xmm15,%xmm5",
                "vpunpcklwd %xmm5,%xmm7,%xmm5",
                "vmovq %rax,%xmm7",
                "vpextrb $4,%xmm2,%eax",
                "shrb %al",
                "movzbl %al,%eax",
                "vpinsrb $4,%eax,%xmm5,%xmm5",
                "shrq $41,%r10",
                "andb $127,%r10b",
                "movzbl %r10b,%eax",
                "vpinsrb $5,%eax,%xmm5,%xmm5",
                "vpunpcklbw %xmm11,%xmm4,%xmm4",
                "vpand %xmm4,%xmm15,%xmm4",
                "vpunpcklwd %xmm4,%xmm5,%xmm4",
                "shrq $41,%rdx",
                "andb $127,%dl",
                "movzbl %dl,%eax",
                "vpinsrb $13,%eax,%xmm3,%xmm3",
                "vpextrb $8,%xmm2,%eax",
                "shrb %al",
                "vpshufb %xmm12,%xmm4,%xmm4",
                "movzbl %al,%eax",
                "vpinsrb $8,%eax,%xmm4,%xmm4",
                "movq %r15,%rax",
                "shrq $9,%rax",
                "andb $127,%al",
                "vpunpcklbw %xmm6,%xmm7,%xmm5",
                "vpand %xmm5,%xmm15,%xmm5",
                "movzbl %al,%eax",
                "vpinsrb $9,%eax,%xmm4,%xmm4",
                "vpextrb $12,%xmm2,%eax",
                "shrb %al",
                "vpslldq $10,%xmm5,%xmm2",
                "vpblendw $32,%xmm2,%xmm4,%xmm2",
                "movzbl %al,%eax",
                "vpinsrb $12,%eax,%xmm2,%xmm2",
                "movq %r15,%rax",
                "shrq $41,%rax",
                "andb $127,%al",
                "movzbl %al,%eax",
                "vpinsrb $13,%eax,%xmm2,%xmm2",
                "movq %r15,%rax",
                "shrq $49,%rax",
                "andb $127,%al",
                "movzbl %al,%eax",
                "vpinsrb $14,%eax,%xmm2,%xmm2",
                "shrq $57,%r15",
                "vpinsrb $15,%r15d,%xmm2,%xmm2",
                "vandps %ymm0,%ymm1,%ymm0",
                "vpunpcklbw %xmm9,%xmm10,%xmm1",
                "vpand %xmm1,%xmm15,%xmm1",
                "vpslldq $14,%xmm1,%xmm1",
                "vpblendw $128,%xmm1,%xmm3,%xmm1",
                "vextractf128 $1,%ymm0,%xmm3",
                "vpaddb %xmm3,%xmm2,%xmm2",
                "vpaddb %xmm0,%xmm1,%xmm0",
                "vinsertf128 $1,%xmm2,%ymm0,%ymm0",
                "popq %rbx",
                ".cfi_def_cfa_offset24",
                "popq %r14",
                ".cfi_def_cfa_offset16",
                "popq %r15",
                ".cfi_def_cfa_offset8"
            ]
        },
        {
            "type": [
                "std::uint64_t",
                "std::uint64_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vextractf128 $1,%ymm0,%xmm1",
                "vpsrlq $1,%xmm1,%xmm1",
                "vpsrlq $1,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddq %xmm3,%xmm1,%xmm1",
                "vpaddq %xmm2,%xmm0,%xmm0",
                "vinsertf128 $1,%xmm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint32_t",
                "std::uint32_t"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vpsrld $1,%xmm0,%xmm1",
                "vextractf128 $1,%ymm0,%xmm0",
                "vpsrld $1,%xmm0,%xmm0",
                "vextractf128 $1,%ymm2,%xmm3",
                "vpaddd %xmm3,%xmm0,%xmm0",
                "vpaddd %xmm2,%xmm1,%xmm1",
                "vinsertf128 $1,%xmm0,%ymm1,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint16_t",
                "std::uint16_t"
            ],
            "instr": [
                "vxorps %ymm0,%ymm1,%ymm2",
                "vmovq %xmm2,%rax",
                "movzwl %ax,%ecx",
                "shrl %ecx",
                "vmovd %ecx,%xmm3",
                "movl %eax,%ecx",
                "shrl $17,%ecx",
                "vpinsrw $1,%ecx,%xmm3,%xmm3",
                "vpextrw $2,%xmm2,%ecx",
                "shrl %ecx",
                "vpinsrw $2,%ecx,%xmm3,%xmm3",
                "vpextrq $1,%xmm2,%rcx",
                "vextractf128 $1,%ymm2,%xmm4",
                "shrq $49,%rax",
                "vpinsrw $3,%eax,%xmm3,%xmm3",
                "vpextrw $4,%xmm2,%eax",
                "shrl %eax",
                "vpinsrw $4,%eax,%xmm3,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $5,%ecx,%xmm3,%xmm3",
                "vpextrw $6,%xmm2,%ecx",
                "shrl %ecx",
                "vpinsrw $6,%ecx,%xmm3,%xmm2",
                "vmovq %xmm4,%rcx",
                "shrq $49,%rax",
                "vpinsrw $7,%eax,%xmm2,%xmm2",
                "vmovd %xmm4,%eax",
                "movzwl %ax,%eax",
                "shrl %eax",
                "vmovd %eax,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $1,%ecx,%xmm3,%xmm3",
                "vpextrw $2,%xmm4,%ecx",
                "shrl %ecx",
                "vpinsrw $2,%ecx,%xmm3,%xmm3",
                "vpextrq $1,%xmm4,%rcx",
                "shrq $49,%rax",
                "vpinsrw $3,%eax,%xmm3,%xmm3",
                "vpextrw $4,%xmm4,%eax",
                "shrl %eax",
                "vpinsrw $4,%eax,%xmm3,%xmm3",
                "movq %rcx,%rax",
                "shrl $17,%ecx",
                "vpinsrw $5,%ecx,%xmm3,%xmm3",
                "vpextrw $6,%xmm4,%ecx",
                "shrl %ecx",
                "vpinsrw $6,%ecx,%xmm3,%xmm3",
                "shrq $49,%rax",
                "vpinsrw $7,%eax,%xmm3,%xmm3",
                "vandps %ymm0,%ymm1,%ymm0",
                "vextractf128 $1,%ymm0,%xmm1",
                "vpaddw %xmm1,%xmm3,%xmm1",
                "vpaddw %xmm0,%xmm2,%xmm0",
                "vinsertf128 $1,%xmm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "std::uint8_t",
                "std::uint8_t"
            ],
            "instr": [
                "pushq %r15",
                ".cfi_def_cfa_offset16",
                "pushq %r14",
                ".cfi_def_cfa_offset24",
                "pushq %rbx",
                ".cfi_def_cfa_offset32",
                ".cfi_offset%rbx,-32",
                ".cfi_offset%r14,-24",
                ".cfi_offset%r15,-16",
                "vxorps %ymm0,%ymm1,%ymm4",
                "vextractf128 $1,%ymm4,%xmm2",
                "vpextrq $1,%xmm2,%r15",
                "vpextrq $1,%xmm4,%rsi",
                "vmovq %xmm2,%rdx",
                "vmovq %xmm4,%rdi",
                "movl %edi,%r8d",
                "movq %rdx,%r14",
                "shldq $47,%rsi,%r14",
                "movq %rsi,%rcx",
                "shldq $55,%rdi,%rcx",
                "shrb %r8b",
                "movq %rsi,%rbx",
                "shldq $47,%rdi,%rbx",
                "vmovq %rbx,%xmm3",
                "vmovq %rcx,%xmm5",
                "vpunpcklbw %xmm3,%xmm5,%xmm5",
                "vmovdqa .LCPI202_0(%rip),%xmm15",
                "vpand %xmm5,%xmm15,%xmm8",
                "movl %edi,%r9d",
                "movq %rdi,%r11",
                "movq %rsi,%rcx",
                "shldq $15,%rdi,%rcx",
                "shrdq $57,%rsi,%rdi",
                "shrl $25,%r9d",
                "vmovq %rdi,%xmm11",
                "movq %rdx,%rdi",
                "shldq $39,%rsi,%rdi",
                "vmovq %rcx,%xmm12",
                "movq %rdx,%r10",
                "vmovq %rdi,%xmm13",
                "movq %rdx,%rdi",
                "shldq $15,%rsi,%rdi",
                "vmovq %r14,%xmm14",
                "movq %rdx,%rcx",
                "shldq $7,%rsi,%rcx",
                "vmovq %rcx,%xmm9",
                "movq %rdx,%rcx",
                "vmovq %rdi,%xmm10",
                "movq %r15,%rdi",
                "shldq $47,%rdx,%rdi",
                "movzbl %r8b,%ebx",
                "vmovd %ebx,%xmm6",
                "movq %r15,%rax",
                "shldq $15,%rdx,%rax",
                "vpunpcklbw %xmm6,%xmm8,%xmm6",
                "vpshufb .LCPI202_1(%rip),%xmm6,%xmm6",
                "vpinsrb $3,%r9d,%xmm6,%xmm6",
                "movq %r15,%rbx",
                "shldq $7,%rdx,%rbx",
                "shrdq $25,%r15,%rdx",
                "vmovq %rdx,%xmm8",
                "vpextrb $4,%xmm4,%edx",
                "shrb %dl",
                "movzbl %dl,%edx",
                "vpinsrb $4,%edx,%xmm6,%xmm6",
                "shrq $41,%r11",
                "andb $127,%r11b",
                "movzbl %r11b,%edx",
                "vpinsrb $5,%edx,%xmm6,%xmm6",
                "vmovq %rdi,%xmm5",
                "vpunpcklbw %xmm11,%xmm12,%xmm3",
                "vpand %xmm3,%xmm15,%xmm3",
                "vpunpcklbw %xmm13,%xmm14,%xmm7",
                "vmovq %rbx,%xmm11",
                "vpextrb $8,%xmm4,%edx",
                "shrb %dl",
                "vpunpcklwd %xmm3,%xmm6,%xmm3",
                "vmovdqa .LCPI202_2(%rip),%xmm12",
                "vpshufb %xmm12,%xmm3,%xmm3",
                "movzbl %dl,%edx",
                "vpinsrb $8,%edx,%xmm3,%xmm3",
                "movq %rsi,%rdx",
                "shrq $9,%rsi",
                "andb $127,%sil",
                "vpand %xmm7,%xmm15,%xmm7",
                "movzbl %sil,%esi",
                "vpinsrb $9,%esi,%xmm3,%xmm3",
                "vpextrb $12,%xmm4,%esi",
                "shrb %sil",
                "vpslldq $10,%xmm7,%xmm4",
                "vpblendw $32,%xmm4,%xmm3,%xmm3",
                "movzbl %sil,%esi",
                "vpinsrb $12,%esi,%xmm3,%xmm3",
                "vmovq %rax,%xmm4",
                "vmovd %xmm2,%eax",
                "shrb %al",
                "movzbl %al,%eax",
                "vmovd %eax,%xmm7",
                "shrq $9,%rcx",
                "andb $127,%cl",
                "movzbl %cl,%eax",
                "vpinsrb $1,%eax,%xmm7,%xmm7",
                "movq %r15,%rax",
                "shrq $25,%rax",
                "vpunpcklbw %xmm8,%xmm5,%xmm5",
                "vmovq %rax,%xmm6",
                "movq %r15,%rax",
                "shrq $17,%rax",
                "vpand %xmm5,%xmm15,%xmm5",
                "vpunpcklwd %xmm5,%xmm7,%xmm5",
                "vmovq %rax,%xmm7",
                "vpextrb $4,%xmm2,%eax",
                "shrb %al",
                "movzbl %al,%eax",
                "vpinsrb $4,%eax,%xmm5,%xmm5",
                "shrq $41,%r10",
                "andb $127,%r10b",
                "movzbl %r10b,%eax",
                "vpinsrb $5,%eax,%xmm5,%xmm5",
                "vpunpcklbw %xmm11,%xmm4,%xmm4",
                "vpand %xmm4,%xmm15,%xmm4",
                "vpunpcklwd %xmm4,%xmm5,%xmm4",
                "shrq $41,%rdx",
                "andb $127,%dl",
                "movzbl %dl,%eax",
                "vpinsrb $13,%eax,%xmm3,%xmm3",
                "vpextrb $8,%xmm2,%eax",
                "shrb %al",
                "vpshufb %xmm12,%xmm4,%xmm4",
                "movzbl %al,%eax",
                "vpinsrb $8,%eax,%xmm4,%xmm4",
                "movq %r15,%rax",
                "shrq $9,%rax",
                "andb $127,%al",
                "vpunpcklbw %xmm6,%xmm7,%xmm5",
                "vpand %xmm5,%xmm15,%xmm5",
                "movzbl %al,%eax",
                "vpinsrb $9,%eax,%xmm4,%xmm4",
                "vpextrb $12,%xmm2,%eax",
                "shrb %al",
                "vpslldq $10,%xmm5,%xmm2",
                "vpblendw $32,%xmm2,%xmm4,%xmm2",
                "movzbl %al,%eax",
                "vpinsrb $12,%eax,%xmm2,%xmm2",
                "movq %r15,%rax",
                "shrq $41,%rax",
                "andb $127,%al",
                "movzbl %al,%eax",
                "vpinsrb $13,%eax,%xmm2,%xmm2",
                "movq %r15,%rax",
                "shrq $49,%rax",
                "andb $127,%al",
                "movzbl %al,%eax",
                "vpinsrb $14,%eax,%xmm2,%xmm2",
                "shrq $57,%r15",
                "vpinsrb $15,%r15d,%xmm2,%xmm2",
                "vandps %ymm0,%ymm1,%ymm0",
                "vpunpcklbw %xmm9,%xmm10,%xmm1",
                "vpand %xmm1,%xmm15,%xmm1",
                "vpslldq $14,%xmm1,%xmm1",
                "vpblendw $128,%xmm1,%xmm3,%xmm1",
                "vextractf128 $1,%ymm0,%xmm3",
                "vpaddb %xmm3,%xmm2,%xmm2",
                "vpaddb %xmm0,%xmm1,%xmm0",
                "vinsertf128 $1,%xmm2,%ymm0,%ymm0",
                "popq %rbx",
                ".cfi_def_cfa_offset24",
                "popq %r14",
                ".cfi_def_cfa_offset16",
                "popq %r15",
                ".cfi_def_cfa_offset8"
            ]
        }
    ]
}